ICFP '18 Paper #21 Author Response
===========================================================================
Paper #21 A Spectrum of Soundness and Performance


General Response
===========================================================================

Thank you for the many comments and suggestions, especially about where our
discussions of related work and future work must improve. See details below.

Review #21B raises serious concerns about works that we failed to cite; namely:

* _A Framework for Object-Oriented Gradual Typing_.
  Chung, Li, Zappa Nardelli, Vitek.
  ECOOP 2018

* _Efficient Gradual Typing_.
  Kuhlenschmidt, Almahallawi, Siek.
  https://arxiv.org/abs/1802.06375

We are familiar with both these works, as Siek and Vitek are co-PIs on a grant
that our second author is PI for (NSF grant SHF 1518844).

For the final version of this paper, we will compare our work to Chung et al.
The main difference between their work and ours is that they do not prove
soundness for their surface languages (only for the core language).

We will not cite Kuhlenschmidt et al. because we are under no obligation to
cite an arXiv paper and (more importantly) we find their performance evaluation
lacking:

- The evaluation for partially-typed programs reports performance relative to
  Racket. This is an apples-to-oranges comparison. As the authors say in
  Section 5.2, "[Grift] does not support a full language".

- The evaluation uses an ad-hoc sampling method, rather than the systematic
  (albiet coarse-grained) methods proposed by Takikawa et al. (2016) and
  Greenman and Migeed (2018). We are not convinced that the Grift sampling
  method supports the strong claims in the paper.

- There are only 6 benchmark programs with data for partially-typed
  configurations; these benchmarks do not include any of the Racket programs
  from Takikawa et al. (2016) or Bauman et al. (2017).

- The data for this paper is not avaiable; it is impossible to tell whether
  the reported running times are on the order of minutes, seconds, or
  milliseconds. (Based on our PI meetings, we suspect it is milliseconds.)

P.S. we will forward this criticism to Kuhlenschmidt et al.


Response to Review #21A
===========================================================================

> A weak part of the paper---which is easy to fix---is that there is no
> discussion of mixed-semantics languages.  As such, Dart is badly characterized
> in this paper as an optional/erasure style language.

We will improve the discussion about Dart and draw attention to mixed-semantics
languages as an area for future work. (It's an area we are excited about.)


> Additionally, because the paper mentions universal types, it seems necessary to
> explicitly clarify (maybe as a footnote) that the discussion of type soundness
> elaborated in this work is syntactic; for migratory/gradual typing to ensure
> (a form of) relational parametricity for universal types is another level of
> complexity, and a very active field of research.

Yes, definitely.


> - In Figure 4, there is quite some redundancy between ->^*_{S-N} and
>   ->^*_{D-N}: would it be possible to further factor out the common parts?

We tried factoring the common parts into a meta-function, but decided it was
better to be simple and clear.


> - Please explain why errors do not propagate through E^\bullet contexts

Errors do propagate through, because E^\bullet is a subset of E.


> - In Theorem 2.0, 2nd reduction alternative, I don't understand why the right
>   hand side cannot be simply: E[dyn t' E* [TagErr]], considering that e' steps
>   to TarErr and that the reduction relation admits reduction under E*.
> (same question for Theorem 2.6)

You are right, thank you.

(The 2nd alternative is an artifact of an earlier version of the semantics.)


> - (l338) "A similar lemma does not hold": would help to state the lemma that
>   does not hold (there is space).

We will elaborate.


> - The data of Figure 12 could be plotted (again, there is space)

Yes, this table is easy to miss.


> - The discussion of the gradual guarantee in section 5 is a bit incomplete.

Thanks for pointing this out.


Response to Review #21B
===========================================================================

> + The paper does a thorough and controlled performance experiment that
>   confirms that the results of Vitousek et al. (2017) on Reticulated
>   Python carry over to the setting of Typed Racket. That is, the
>   transient semantics avoids the catastrophic performance problems
>   that occur in naive implementations of the natural approach, but
>   transient incurs overhead in statically typed code.

Remarks like this are exactly why we prepared this paper. It is time to stop
putting broad claims about different languages with different type systems and
different guarantess in the scientific literature.

Vitousek et al. (2017) does not directly compare transient to natural.


> * The semantic framework is a straightforward adaptation of
>   the Matthews-Findler multi-language semantics.

The first sentence of Section 2.2 and first paragraph of Section 6
(the conclusion) acknowledge Matthews & Findler. If this is not enough,
we can add more.


> * Theorem 2.0 is a just a combination of the usual Type Safety theorem
>   for gradually typed languages (Siek and Taha 2006) and the Blame
>   Theorem (Tobin-Hochstadt and Felleisen 2006, Wadler and Findler
>   2009). The paper does not discuss these relationships.

The paper does not claim that these theorems are novel. The important
contribution is expressing the different approaches in a framework that
draws attention to their meaningful distinctions.

That said, the difference between Theorem 2.0 and prior work is that it
explicitly connects the surface language (without proxy/monitor values) to the
core language (with proxy values). This is an important distinction for
language designers: even if the surface language does not expose proxies,
users need to understand proxies to understand the language's soundness
guarantee.


> * Theorems 2.1, 2.3, and 2.4 are all the usual type safety theorem for
>   dynamically typed languages.

Again, the paper does not claim these theorems are novel but it is definitely
**unusual** that these theorems include 2 typing judgments.

These theorems also emphasize that soundness for a pair of languages comes
as a pair of theorems. (Non-experts should be wary of papers that advertise
a "Theorem 2.5"-style result without discussing partially-typed programs.)


> * Theorem 2.5 is just type safety for a statically typed program, and
>   is a corollary of the equivalence between gradual typing and static
>   typing on fully annotated programs (Siek et al. 2015).  The paper
>   does not discuss this close relationship.

Good point, we will discuss the relationship.


> * Theorem 2.6 is an adaptation of Corollary 5.5.1 (Type soundness) of
>   Vitousek et al. (2017).  The paper does not discuss this close
>   relationship.

Theorem 2.6 is **not** an adaptation of Vitousek et al.'s "type soundness".
Vitousek et al.'s Corollary 5.5.1 is about a single language.

Nor is our Theorem 2.6 an adaptation of Vitousek et al.'s Theorem 5.5
(Open-World Soundness). There are two important differences:

- Vitousek et al. do not define a type system for the surface language;
  it is impossible to reason about programs independent of their core-language
  translation (via Vitousek's $\rightsquigarrow$).

- Vitousek et al.'s "stuck terms" are defined in terms of the core language;
  it is not clear that typed programs cannot get stuck without studying their
  translation into the core language. In contrast, our framework makes it
  clear that only a dynamically-typed subexpression can step to a TagError.

We will add a clarification to the paper.


> * Theorem 2.7 should be another example of the usual type safety
>   theorem for a dynamically typed language, but it looks like there
>   is a typo in saying |-_{LD} v : \lfloor \tau \rfloor
>   because there is no \tau to refer to here.

Thank you, that is definitely a typo.


> p1. The abstract is much too short.

The abstract says just what we choose it to say --- nothing more.

If you believe something is missing from the abstract, we will consider
including it.


> p1. "But, it may impose a huge run-time cost"
> It would be appropriate to cite recent work by Kuhlenschmidt et
> al. (see above) that shows that the natural semantics does not have to
> impose a huge run-time cost.

We disagree, it would not be appropriate to cite Kuhlenschidt et al. here.
The sentence you quote is trying to communicate the **historical fact** that
the performance of the natural embedding led researchers and implementors
to consider other alternatives.

Kuhlendschmidt et al.'s work does not change the past.


> p1. In the discussion of "type soundness", this paper should discuss
> the Blame Theorem, which provides the same guarantees that are provided
> by the theorems in this paper.

All the blame theorems we know (see below) are guarantees about casts in an
intermediate language. Our type soundness theorems are guarantees about the
results of evaluating a surface-language term. These are different guarantees.

"The Blame Theorem"s:

- Wadler and Findler (2009)
- Ahmed et al. (2011)
- Vitousek et al. (2017)


> p9. "Second, monitoring adds prohibitive run-time cost."
> That is only true of naive implementations. Again, see
> Kuhlenschmidt et al.

Kuhlenschmidt et al's work is not relevant here --- the sentence you quote is
summarizing the motivation for transient given in Vitousek et al. (2017).

Please let us know if you believe we have mis-represented Vitousek et al. (2017)


> p4. It is confusing to use boundary errors for both cast errors and
> for errors such as div-by-zero.

We do this to show how soundness for a pair of languages is a natural
generalization of soundness for a single language (i.e., a language that
includes primitive operations such as division in its trusted code base).

We will clarify in the paper.


> p9. "near-constant time"
> Why only "near" and not just "constant time"?

One reason is for union types. The check for `(U String Integer)` must perform
at most two constructor checks at runtime.

Another reason, from Vitousek et al. (2017), is for structural object types.
Checking that an object has the expected members requires one check for each
member in the structural type.


> p10.
> Why do you perform checking of parameters in the reduction rules
> but insert all the other checks during compilation? This seems
> rather inconsistent and differs, as you later point out,
> from the implementations.

Footnote 3 (line 537) explains.


> p16.
> "This table demonstrates that for pathological examples..."
> Those examples are not pathological.

Suggestions welcome. We just want a word to describe "examples with worst-case
performance".


> p17. "the implicit conjectures of the literature"
> You seem to be overlooking the performance experiments
> reported on by Vitousek et al. (2017).

Vitousek et al. (2017) do not measure the performance of programs that mix
typed and untyped code.


> p19. "The natural embedding incurs three significantly larger kinds of
> costs." You're forgetting the fourth: the natural embedding also has
> the space-efficiency problem pointed out by Herman et al. (2006),
> which also induces problems with time efficiency.

We did not forget, but you are right we need to be clearer that the cost
of **allocation** is a space+time cost and is unbounded in principle.

We will elaborate in Section 4.5.


> p19. "Sound static types can eliminate the need to dispatch, thus the
> natural embedding's performance can exceed that of the erasure
> embedding"
>
> This paper does not provide empirical results regarding this claim.

See Figure 12.


Response to Review #21C
===========================================================================

> I am a little bit surprised at the fact that static typing does not
> contribute the runtime performance at all.  I would like to see the
> runtime performance on a JIT compiler or a compiler equipped with
> type-conscious optimization.

Typed Racket does do some type-conscious optimization, and Figure 12 shows
that this optimization can make a fully-typed program run faster than a
type-erased program.

Agreed though, it would be very interesting to see similar results for a
language with a type-aware JIT compiler. Future work!
