ICFP '18 Paper #21 Author Response
===========================================================================

Review #21B mischaracterizes our results in at least three ways.

FIRST, the review misrepresents our theoretical results as variations of
known theorems.

This claim is _wrong_. Our theorems articulate statements from the existing
literature in a single framework, making them comparable. [[ We clearly
must explicate how each section relates to prior literature directly. ]] On
this apples-to-apples platform, our theorem statements expose the looseness
of previous statements in the literature concerning "soundness" in the area
of gradual typing. Our three pairs of theorems explain that the statements in
the literature denote distinct notions of soundness and must be read very
carefully. For technical details, see below.

SECOND, the review #21B seems to imply that our results might be preempted
by two papers (one of which is still unavailable in public):

> _A Framework for Object-Oriented Gradual Typing_.
>  Chung, Li, Zappa Nardelli, Vitek.
>  ECOOP 2018
>
> _Efficient Gradual Typing_.
> Kuhlenschmidt, Almahallawi, Siek.
> https://arxiv.org/abs/1802.06375

Felleisen is the PI on a large NSF grant that also supports these efforts.
The papers were presented at the August 2017 PI day at Northeastern. When
we submitted our paper, Chung et al.'s work was NOT ACCEPTED and NOT
AVAILABLE in public. [[ We confirmed this statement with the authors who
sit across the hallway from us. ]]  Once its status is changed, we will
compare the two research results in the paper.

Kuhlenschmidt et al. are working on an alternative approach to the compilation
of NEWLY DESIGNED gradually typed languages. The language is a work-in-progress;
indeed, the paper warns readers not to use the compiler "because it does not
support a full language" (p. 10, left). Their work compares two kinds of
references and two kinds of casts on an ad-hoc sample of mixed-typed
configurations derived from 6 micro-benchmarks.

But, we do not accept that this status report preempts any of our practical
results. Kuhlenschmidt et al.'s work does not include an apples-to-apples
comparison with full-fledged implementations of the three major semantics.
Similarly, while our evaluation measures non-trivial benchmarks,
Kuhlenschmidt et al.'s compiler cannot handle most of the shootout benchmarks.

THIRD, the review claims that our paper does not support our statements
about performance. Specifically, the review claims 

> p19. "Sound static types can eliminate the need to dispatch, thus the
> natural embedding's performance can exceed that of the erasure
> embedding"
> This paper does not provide empirical results regarding this claim.

FIGURE 12 on PAGE 15 (LINE 730) clearly demonstrates that the
performance of NATURAL dominates the performance of ERASURE on programs
when the typed-driven optimizer can exploit sound information.


Response to Review #21A
===========================================================================

> A weak part of the paper---which is easy to fix---is that there is no
> discussion of mixed-semantics languages.  As such, Dart is badly characterized
> in this paper as an optional/erasure style language.

Thank you for reminding us of Dart's mixed approach. We will include a
brief discussion and draw attention to its approach, also as an area for
future work.


> - Please explain why errors do not propagate through E^\bullet contexts

Errors do propagate through, because E^\bullet is a subset of E.


> - In Theorem 2.0, 2nd reduction alternative, I don't understand why the right
>   hand side cannot be simply: E[dyn t' E* [TagErr]], considering that e' steps
>   to TarErr and that the reduction relation admits reduction under E*.
>   (same question for Theorem 2.6)

You are correct. Thanks!


> - The data of Figure 12 could be plotted (again, there is space)

Yes! This table is too easy to miss.


Response to Review #21C
===========================================================================

> I am a little bit surprised at the fact that static typing does not
> contribute the runtime performance at all.  I would like to see the
> runtime performance on a JIT compiler or a compiler equipped with
> type-conscious optimization.

This is a correct observation. The Indiana Typed Racket team is revising
the Pycket compiler for Racket to address this issue. We are looking
forward to reproducing our experimental work on top of that new
backend. But this area remains future work for sound gradually typed
approaches.


Response to Review #21B
===========================================================================

> + The paper does a thorough and controlled performance experiment that
>   confirms that the results of Vitousek et al. (2017) on Reticulated
>   Python carry over to the setting of Typed Racket. That is, the
>   transient semantics avoids the catastrophic performance problems
>   that occur in naive implementations of the natural approach, but
>   transient incurs overhead in statically typed code.

Vitousek et al. (2017) do not directly compare transient to natural.

Remarks like this are exactly why we prepared this paper. It is time to stop
making unscientific claims about different languages with different type
systems and different guarantees.


> * The semantic framework is a straightforward adaptation of
>   the Matthews-Findler multi-language semantics.

The first sentence of Section 2.2 and first paragraph of Section 6 acknowledge
Matthews and Findler.


> * Theorem 2.0 is a just a combination of the usual Type Safety theorem
>   for gradually typed languages (Siek and Taha 2006) and the Blame
>   Theorem (Tobin-Hochstadt and Felleisen 2006, Wadler and Findler
>   2009). The paper does not discuss these relationships.

Incorrect. The usual type soundness theorems relate ONE typing property to a
semantics. Theorem 2.0 relates a surface-language typing property to a DIFFERENT
evaluation-language property and a semantics. [[ Critically, surface-language
typing is not preserved by the semantics. ]]

To clarify our point from the general response above, theorems 2.0, 2.3, and 2.6
demonstrate how the various "type soundness" theorems from the literature are
superficially similar, but rely on fundamentally different evaluation-language
typing properties.

We will explain these important subtleties in the paper.


> * Theorems 2.1, 2.3, and 2.4 are all the usual type safety theorem for
>   dynamically typed languages.

Incorrect. The "usual" type safety theorem relates ONE safety property to
a semantics. In contrast, theorems 2.1, 2.3, and 2.4 relate a surface-language
safety property to an evaluation-language safety property and semantics.
An evaluation-language property is NECESSARY to handle the run-time interactions
between typed and untyped code, and its meaning DEPENDS on the desired notion of
type soundness.


> * Theorem 2.5 is just type safety for a statically typed program, and
>   is a corollary of the equivalence between gradual typing and static
>   typing on fully annotated programs (Siek et al. 2015).  The paper
>   does not discuss this close relationship.

Correct, we will discuss the relationship.


> * Theorem 2.6 is an adaptation of Corollary 5.5.1 (Type soundness) of
>   Vitousek et al. (2017).  The paper does not discuss this close
>   relationship.

Theorem 2.6 is NOT an adaptation of Vitousek et al.'s "type soundness".
Vitousek et al.'s Corollary 5.5.1 is about a single language.

Nor is our Theorem 2.6 a simple adaptation of Vitousek et al.'s Theorem 5.5
(Open-World Soundness):

- Vitousek et al. do not define a type system for the surface language;
  it is impossible to reason about programs in their system independent of the
  translation from surface to core (via Vitousek et al.'s $\rightsquigarrow$).

- Vitousek et al.'s "stuck terms" are defined in terms of the core language;
  it is not clear from their theorem that well-typed expressions cannot get
  stuck. Again, one must study the translation of surface-language expressions
  into the core language. In contrast, our theorems clearly state the
  different guarantees for statically-typed and dynamically-typed expressions.

We will add a clarification to the paper.


> * Theorem 2.7 should be another example of the usual type safety
>   theorem for a dynamically typed language, but it looks like there
>   is a typo in saying |-_{LD} v : \lfloor \tau \rfloor
>   because there is no \tau to refer to here.

Thank you, that is definitely a typo.


> p1. The abstract is much too short.

Why?


> p1. "But, it may impose a huge run-time cost"
> It would be appropriate to cite recent work by Kuhlenschmidt et
> al. (see above) that shows that the natural semantics does not have to
> impose a huge run-time cost.

We disagree, it would not be appropriate to cite Kuhlenschmidt et al. here.
The sentence above is trying to communicate the historical fact that the
performance of the natural embedding led researchers and implementors to
consider other alternatives. Kuhlenschmidt et al.'s work does not change the
past.


> p1. In the discussion of "type soundness", this paper should discuss
> the Blame Theorem, which provides the same guarantees that are provided
> by the theorems in this paper.

None of the blame theorems (that we know) provide the same guarantees.

The blame theorems in Wadler and Findler (2009), Ahmed et al. (2011), and
Vitousek et al. (2017) are guarantees about casts in an intermediate language.
Our soundness theorems are guarantees about the results of evaluating a
surface-language term. These are different guarantees.


> p9. "Second, monitoring adds prohibitive run-time cost."
> That is only true of naive implementations. Again, see
> Kuhlenschmidt et al.

Kuhlenschmidt et al's work is not relevant here --- the sentence above is
summarizing the motivation for transient given in Vitousek et al. (2017).

Please let us know if you believe we have mis-represented Vitousek et al. (2017)


> p4. It is confusing to use boundary errors for both cast errors and
> for errors such as div-by-zero.

Cast errors and div-by-zero errors are the same kind of error. They
both arise when one language sends invalid data to another.

In other words, soundness for a pair of languages is a natural generalization
of soundness for a single language that includes primitive operations
(such as division) in its trusted code base.

We will clarify in the paper.


> p9. "near-constant time"
> Why only "near" and not just "constant time"?

One reason is for union types. The check for `(U String Integer)` must perform
at most two constructor checks at runtime.

Another reason, from Vitousek et al. (2017), is for structural object types.
Checking that an object has the expected members requires one check for each
member in the structural type.


> p10.
> Why do you perform checking of parameters in the reduction rules
> but insert all the other checks during compilation? This seems
> rather inconsistent and differs, as you later point out,
> from the implementations.

Footnote 3 (line 537) explains.


> p16.
> "This table demonstrates that for pathological examples..."
> Those examples are not pathological.

Suggestions welcome. We just want a word to describe "examples with worst-case
performance".


> p17. "the implicit conjectures of the literature"
> You seem to be overlooking the performance experiments
> reported on by Vitousek et al. (2017).

Vitousek et al. (2017) do not measure the performance of programs that mix
typed and untyped code.


> p19. "The natural embedding incurs three significantly larger kinds of
> costs." You're forgetting the fourth: the natural embedding also has
> the space-efficiency problem pointed out by Herman et al. (2006),
> which also induces problems with time efficiency.

We did not forget, but you are right we need to be clearer that the cost
of ALLOCATION is a space+time cost and is unbounded in principle.

We will clarify.

> The paper should describe its relationship with [Chung et al. 2018]

Chung et al. (2018) define a calculus for object-oriented gradual typing and
present four translations from a common surface language into the calculus.
Through various examples, they demonstrate how the different translations can
lead to core-calculus programs with different semantics. In contrast to our
work, Chung et al. do not prove type soundness in terms of the surface language
and do not evaluate the performance of their translations.

